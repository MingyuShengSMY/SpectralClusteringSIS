{
    "method_name": "DeepSpectral",
    "method_config_dict": {
        "repo": "facebookresearch/dino:main",
        "name": "dino_vits8",
        "__candidate_names__": ["dino_resnet50", "dino_vitb16", "dino_vitb8",
            "dino_vits16", "dino_vits8", "dino_xcit_medium_24_p16", "dino_xcit_medium_24_p8",
            "dino_xcit_small_12_p16", "dino_xcit_small_12_p8", "resnet50"],
        "eigen_vectors_k": 15,
        "cluster_k": 15
    },
    "crf_mark": false,
    "task": "semantic",
    "dataset_list": [
        {
            "name": "ARTNetDataset",
            "image_dataset": true,
            "train_val_test_split_ratio": [0.7, 0.1, 0.2],
            "__comment1__": [
                "it's a dict={'train': ['video_name', ...], 'val': [], 'test': []}",
                "If train, val and test have the same video name, the frames in the video will be split",
                "according to the split ratio"
            ],
            "set_split_preset": {
                "train": ["set1"],
                "val": ["set1"],
                "test": ["set2"]
            },
            "use_for_train": [
            ],
            "use_for_val": [
            ],
            "use_for_test": [
                "test_separate_samples.txt", "sample_samples.txt"
            ],
            "__comment2__":  "Empty if no black edge",
            "valid_field_left_top": [
            ],
            "valid_field_size": [
            ]
        },
        {
            "name": "EndoVis2017",
            "image_dataset": false,
            "train_val_test_split_ratio": [0.7, 0.1, 0.2],
            "__comment1__": [
                "it's a dict={'train': ['video_name', ...], 'val': [], 'test': []}",
                "If train, val and test have the same video name, the frames in the video will be split",
                "according to the split ratio"
            ],
            "set_split_preset": {
                "train": ["instrument_dataset_1", "instrument_dataset_2","instrument_dataset_3","instrument_dataset_4","instrument_dataset_5","instrument_dataset_6","instrument_dataset_7","instrument_dataset_8"],
                "val": ["instrument_dataset_1", "instrument_dataset_2","instrument_dataset_3","instrument_dataset_4","instrument_dataset_5","instrument_dataset_6","instrument_dataset_7","instrument_dataset_8"],
                "test": ["instrument_dataset_1_test", "instrument_dataset_2_test","instrument_dataset_3_test","instrument_dataset_4_test","instrument_dataset_5_test","instrument_dataset_6_test","instrument_dataset_7_test","instrument_dataset_8_test","instrument_dataset_9","instrument_dataset_10"]
            },
            "use_for_train": [
            ],
            "use_for_val": [
            ],
            "use_for_test": [
                "test_separate_samples.txt", "sample_samples.txt"
            ],
            "valid_field_left_top": [
                28,
                320
            ],
            "valid_field_size": [
                1024,
                1280
            ]
        },
        {
            "name": "EndoVis2018",
            "image_dataset": false,
            "train_val_test_split_ratio": [0.7, 0.1, 0.2],
            "__comment1__": [
                "it's a dict={'train': ['video_name', ...], 'val': [], 'test': []}",
                "If train, val and test have the same video name, the frames in the video will be split",
                "according to the split ratio"
            ],
            "set_split_preset": {
                "train": ["seq_1", "seq_2","seq_3","seq_4","seq_5","seq_6","seq_7","seq_9","seq_10","seq_11","seq_12","seq_13","seq_14","seq_15","seq_16"],
                "val": ["seq_1", "seq_2","seq_3","seq_4","seq_5","seq_6","seq_7","seq_9","seq_10","seq_11","seq_12","seq_13","seq_14","seq_15","seq_16"],
                "test": ["seq_17","seq_18","seq_19","seq_20"]
            },
            "use_for_train": [
            ],
            "use_for_val": [
            ],
            "use_for_test": [
                "test_separate_samples.txt", "sample_samples.txt"
            ],
            "valid_field_left_top": [
            ],
            "valid_field_size": [
            ]
        },
        {
            "name": "UCL",
            "image_dataset": false,
            "train_val_test_split_ratio": [0.7, 0.1, 0.2],
            "__comment1__": [
                "it's a dict={'train': ['video_name', ...], 'val': [], 'test': []}",
                "If train, val and test have the same video name, the frames in the video will be split",
                "according to the split ratio"
            ],
            "set_split_preset": {
                "train": ["Video_01", "Video_02","Video_03","Video_04","Video_05","Video_06","Video_07","Video_08","Video_09","Video_10","Video_11","Video_12","Video_13","Video_14","Video_15","Video_16"],
                "val": ["Video_01", "Video_02","Video_03","Video_04","Video_05","Video_06","Video_07","Video_08","Video_09","Video_10","Video_11","Video_12","Video_13","Video_14","Video_15","Video_16"],
                "test": ["Video_17","Video_18","Video_19","Video_20"]
            },
            "use_for_train": [
            ],
            "use_for_val": [
            ],
            "use_for_test": [
                "test_separate_samples.txt", "sample_samples.txt"
            ],
            "__comment2__":  "Empty if no black edge",
            "valid_field_left_top": [
            ],
            "valid_field_size": [
            ]
        },
        {
            "name": "CholecSeg8k",
            "image_dataset": false,
            "train_val_test_split_ratio": [0.7, 0.1, 0.2],
            "__comment1__": [
                "it's a dict={'train': ['video_name', ...], 'val': [], 'test': []}",
                "If train, val and test have the same video name, the frames in the video will be split",
                "according to the split ratio"
            ],
            "set_split_preset": {
            },
            "use_for_train": [
            ],
            "use_for_val": [
            ],
            "use_for_test": [
                "test_separate_samples.txt", "sample_samples.txt"
            ],
            "__comment2__":  "Empty if no black edge",
            "valid_field_left_top": [
            ],
            "valid_field_size": [
            ]
        }
    ],

    "dataset_dir": {
        "root": "dataset",
        "inputX": "inputX",
        "originalImage": "inputX/originImage",
        "__comment5__": "it will be groundtruth/task",
        "groundTruth": "groundTruth",
        "output": "output",
        "samples": "samples"
    },
    "log_dir": "logs",

    "__comment3__": "path_to_model_file",
    "load_model_mark": false,
    "model_load_from": "saved_models",
    "model_save_dir": "saved_models",

    "__comment1__": "empty if no need, dividable by 32 for AGSD",
    "model_input_size": [
        512,
        640
    ],
    "model_output_class_num": 2,
    "data_augmentation": false,
    "model_input_channel": 3,
    "loss_detail_key_list": ["Loss_Sum","Loss_Anchor", "Loss_Diffusion"],
    "__comment4__": "for video dataset, the number of extra frames, [-1, 1] means 3 frames used including the mid one",
    "train_frame_left_right": [
        0,
        0
    ],
    "test_frame_left_right": [
        0,
        0
    ],

    "epoch_num": 100,
    "checkpoint_per_epoch_num": 1,
    "early_stop_patience": 10,

    "batch_size": 6,
    "batch_size_te": 1,
    "num_workers": 8,

    "optimizer": "Adam",
    "learning_rate": 0.0005,
    "lr_beta1": 0.9,
    "lr_beta2": 0.999,

    "metrics": [
            "mIoU",
            "Acc",
            "Dice",
            "Time Cost Per Image",
            "FPS",
            "Params"
        ],

    "binary_seg_threshold": 0.0,

    "random_seed": 2024,

    "gpu_mark": true,

    "verbose": true
}